---
title: "P8105_hw3_my2838"
output: github_document
---

```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
```

# Problem 1

```{r}
library(p8105.datasets)
data("instacart")
```

*How many aisles are there, and which aisles are the most items ordered from?*

```{r}
aisle = pull(instacart, aisle) 
# number of aisle
unique (aisle) |>
  length ()

# find the item most ordered
freq = table(aisle) 
names(freq)[which.max(freq)]
```

**Comments:** There are 134 aisles, and the most items ordered is **fresh vegetables**.


*Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.*

```{r}
aisle_df = as.data.frame (freq)
colnames(aisle_df) = c("aisle","freq")

aisle_df |>
  subset( freq > 10000) |>
  ggplot(aes(x = aisle, y = freq)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5))
```

**Comments:** From the graph, we can know there are a lot of aisles with more than 10000 items ordered, but most of them are ordered under 50000 times. The numbers of items brought in fresh vegetables and fresh fruits aisles aisles are significantly exceeded the others.

*Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.*

```{r}
instacart |>
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") |>
  group_by(aisle) |>
  count(product_name) |>
  mutate(rank = min_rank(desc(n))) |>
  filter(rank < 4) |>
  arrange(aisle, rank) |>
  rename(times = n) |>
  knitr::kable()
```

**Comments:** For baking ingredients aisle, the most popular item is Light Brown Sugar, the second popular item is Pure Baking Soda and the third popular item is Cane Sugar.

For dog food care aisle, the most popular item is Snack Sticks Chicken & Rice Recipe Dog Treats, the second popular item is Organix Chicken & Brown Rice Recipe and the third popular item is Small Dog Biscuits.

For packaged vegetables fruits aisle, the most popular item is Organic Baby Spinachs, the second popular item is Organic Raspberries and the third popular item is Organic Blueberries.

*Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).*

```{r}
instacart |>
  filter(product_name == "Pink Lady Apples"| product_name == "Coffee Ice Cream") |>
  group_by(product_name, order_dow) |>
  summarize(mean_hours = mean(order_hour_of_day), .groups = "drop") |>
  mutate( order_dow = factor(order_dow,
                             labels = c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hours) |>
  knitr::kable()
```

**Comments:** Generally, the time of ordering Coffee Ice Cream is longer than Pink Lady Apples.

Coffee Ice Cream was ordered more between Tuesday to Thursday, while the Pink Lady Apples were ordered more on Sunday and Wednesday.

# Problem 2

First, do some data cleaning. 

```{r}
library(p8105.datasets)
data("brfss_smart2010") 

# Data Cleaning
brfss = 
  brfss_smart2010 |>
  janitor::clean_names()  |>
  filter(
  topic == "Overall Health", 
  response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")
  ) |>
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

*In 2002, which states were observed at 7 or more locations? What about in 2010?*

```{r}
  brfss |>
  group_by(year, locationabbr) |>
  summarise(count = n_distinct(locationdesc), .groups = "drop") |>
  filter(count >= 7)|>
  filter( year == 2002 | year == 2010) |>
  group_by(year) |>
  mutate(rank = min_rank(desc(count))) |>
  rename(state = locationabbr ) |>
  arrange(year, rank) |>
  knitr::kable()
```

In 2002, PA, MA, NJ, CT, FL, NC were observed at 7 or more locations.
In 2010, FL, NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA, SC were observed at 7 or more locations.

**Comments:** We can see more states were observed at 7 or more locations in 2010 compared to 2002. And the observed locations are increased too.


*Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).*

```{r}
  brfss |>
  filter(response == "Excellent") |>
  group_by(year, locationabbr) |>
  summarise(average_value = mean(data_value, na.rm = TRUE), .groups = "drop") |>
  ggplot( aes(x = year, y = average_value, group = locationabbr, color = locationabbr)) +
  geom_line(alpha = .5)  +
  labs(title = "Average Value of 'Excellent' Responses Over Time", 
       x = "Year", y = "Average Value") +
  theme_bw()
```

**Comments:** The average value of 'Excellent' Responses in every states are fluctuate over time.

*Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.*

```{r}
  brfss |>
  filter(locationabbr == "NY", year == 2006 | year == 2010) |>
  ggplot( aes(x = response, y = data_value, fill = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  labs(
    title = "Distribution of data_value for Responses in NY in 2006 & 2010",
    x = "Response",
    y = "Data Value"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5))

```

**Comments:** In both two years, 'Poor' appears least frequently. And the response 'Fair' is less than other 3 responses too. The most popular responses are 'Good' and 'Very Good', both over 30. The difference between 2006 and 2010 is that the number of responses 'Very Good' grew over time.



# Problem 3

Load, tidy, merge, and otherwise organize the data sets.

```{r}
covar =
  read_csv("data/nhanes_covar.csv", skip = 4, show_col_types = FALSE) |>
  janitor::clean_names() |>
  filter(age >= 21) |>
  drop_na() |>
  mutate(education = case_when(
    education == 1 ~ "Less than high school",
    education == 2 ~ "High school equivalent",
    education == 3 ~ "More than high school"
  ),
  sex = case_when(
    sex == 1 ~ "Male",
    sex == 2 ~ "Female"
  ))
```

Produce a reader-friendly table for the number of men and women in each education category.

```{r}
covar |>
  group_by (sex, education) |>
  summarize(count = n(), .groups = "drop") |>
  pivot_wider(
    names_from = sex,
    values_from = count
  ) |>
  knitr::kable()
```

Create a visualization of the age distributions for men and women in each education category.

```{r}
#Visualization of Age Distribution
ggplot(covar, aes(x = education, y = age, fill = sex)) +
  geom_boxplot() +
  labs(title = "Age Distribution by Gender and Education",
       x = "Education Level",
       y = "Age") +
  theme_bw() 
```

**Comments:**
From the table, there are far more participants with a high school education than any other education. The participants with high school equivalent are more males than females, but for the other education level the numbers of participants of both genders are equal.


From the boxplot, participants with more than high school degree are younger. Specifically, females participants were older than males among participants with a high school equivalent, while males and females were about the similar age among other levels.


Using the tidied dataset, aggregate across minutes to create a total activity variable for each participant.

```{r}
accel =
  read_csv("data/nhanes_accel.csv", show_col_types = FALSE) |>
  janitor::clean_names() 
accel = 
  mutate(accel, activity = rowSums(accel[, -1])) |>
  select(seqn, activity, everything())

nhanes = inner_join(covar, accel, by = "seqn")

```

Plot these total activities (y-axis) against age (x-axis), compare men to women and have separate panels for each education level.
 
```{r}
ggplot(nhanes, aes(x = age, y = activity, color = sex)) +
  geom_point(alpha = .5, size = .5) +
  geom_smooth(linewidth = .5) +
  facet_wrap(. ~education) +
  labs(title = "Total Activity by Age, Gender and Education Level", x = "Age", y = "Total Activity") +
  theme_bw()
```


**Comments:** There is a correlation between age and activity, where the older the people are (around 60 years old), the less active they are. But there is no direct relationship between the education level and activity. Overall, we can assume that the female participants are more active than male. 


Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex.

```{r}
mean_act = 
  nhanes |>
  group_by (education, sex) |>
  summarise(across(starts_with("min"), ~ mean(.), .names = "mean_{.col}"), .groups = "drop") |>
  pivot_longer(cols = starts_with("mean_"), names_to = "time", values_to = "mean")|>
  mutate(
    time = substring(time, 9),
    time = as.numeric(time)
  )

ggplot(mean_act, aes(x = time/60 , y = mean, color = sex)) +
  geom_line(linewidth = .5, alpha = .5) +
  geom_smooth(method = "gam", linewidth = .5) +
  facet_grid(. ~education) +
  labs(title = "Activity by Education Level and Gender in 24 hours", 
       x = "Time(in hours)",
       y = "Mean Activity") +
  theme_bw()
```

**Comments:** Generally, the female participants are more active than male though the whole day.All participants were least active at 5 and most active during the day (10-20) compared to the night times.
